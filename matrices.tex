\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}

\title{Merkintöjä}
\author{heikkila.elias }
\date{November 2021}

\setlength{\parindent}{0em}
\begin{document}
	First of all. Let's recall that Walsh-Hadamard matrix can be written in a form (where this product form is proved?)
	\begin{align*}
		\mathbf{H} = \prod_{j=1}^m \frac{1}{\sqrt{2}} (\mathbf{I} + i\mathbf{E}(\mathbf{e}_j, \mathbf{e}_j))
	\end{align*}
	
	Now by simply opening the product, we get
	\begin{align*}
		\prod_{j=1}^m \frac{1}{\sqrt{2}} (\mathbf{I} + i\mathbf{E}(\mathbf{e}_j, \mathbf{e}_j)) = \frac{1}{\sqrt{N}} \sum_{a \in \mathbb{F}^m_2} i^{w(\mathbf{a})}\mathbf{E}(\mathbf{a},\mathbf{a}).
	\end{align*}
	
	Walsh-Hadamard matrix belongs to the Clifford group as it permutes the Pauli group. Walsh-Hadamard matrix corresponds to the symplectic matrix $\mathbf{F} = \begin{bmatrix}
		\mathbf{0} & \mathbf{I} \\
		\mathbf{I} & \mathbf{0}
	\end{bmatrix}$
	so this means that if we conjugate $\mathbf{E}(\mathbf{a},\mathbf{b})$ with the Walsh-Hadamard matrix $\mathbf{H}$, we will swap the places of $\mathbf{a}$ and $\mathbf{b}$: $\mathbf{H}^H\mathbf{E}(\mathbf{a},\mathbf{b})\mathbf{H} = \pm \mathbf{E}(\left[\mathbf{a},\mathbf{b}\right]\mathbf{F}) = \pm \mathbf{E}(\mathbf{b},\mathbf{a})$. Now it is clear that Walsh-Hadamard matrix gives an isomorphism between the $\mathcal{X}$-group: $X = \{E(a,0) \mid a \in \mathbb{F}^m_2 \}$ and $Z$-group: $Z = \{E(0,b) \mid b \in \mathbb{F}^m_2 \}$ since $H^HXH = Z$.
	
	Now the symplectic matrix $T_S = \begin{bmatrix} I & S \\ 0 & I \end{bmatrix}$, where $S$ is a binary symmetric matrix, corresponds to the Clifford operator $g = \text{diag}(i^{vSv^T})$. (This is where the generalization happens when we consider arbitrary binary matrices or matrices with half-elements in the generalized setting).
	
	When we conjugate Walsh-Hadamard matrix with $g$, we get a matrix of codewords determined by $S$, where the codewords are the columns (or rows) of the following matrix:
	\begin{align*}
		&W = g^HHg = \frac{1}{\sqrt{N}}g^H\left(\sum_{a \in \mathbb{F}^m_2} i^{w(a)}E(a,a)\right)g = \frac{1}{\sqrt{N}}\sum_{a \in \mathbb{F}^m_2} i^{w(a)}g^HE(a,a)g = \\ &\frac{1}{\sqrt{N}}\sum_{a \in \mathbb{F}^m_2} i^{w(a)}E(\left[a,a\right]T_S) = \frac{1}{\sqrt{N}}\sum_{a \in \mathbb{F}^m_2} i^{w(a)}E(a,aS + a)
	\end{align*}
	
	Now we can also write this in a product form
	\begin{align*}
		\frac{1}{\sqrt{N}} \sum_{a \in \mathbb{F}^m_2} i^{w(a)}E(a,aS + a) = \prod_{j = 1}^m\frac{1}{\sqrt{2}}  (-1)^{k_{S, j}}iE(e_j, e_j(S + 1))
	\end{align*}
	where $(-1)^{k_{S, j}}$ is sign determined by $S$ and $j$. This form is not needed for now, but might be handy sometimes. One would have to still find out the sign which is due to the fact that we might need to swap the orders of the $X$ and $Z$ matrices in the tensor product in order to get into the definition of $E(a, aS + a)$.
	
	Now calculate a "shift" of the codeword matrix:
	\begin{align*}
		E(e_j, 0)W = \frac{1}{\sqrt{N}} \sum_{a \in \mathbb{F}^m_2} i^{w(a)}E(e_j,0)E(a,aS + a) = \frac{1}{\sqrt{N}} \sum_{a \in \mathbb{F}^m_2} i^{w(a)}i^{-e_j(aS + a)}E(a + e_j,aS + a)  = \\ \frac{1}{\sqrt{N}} \sum_{a \in \mathbb{F}^m_2} i^{w(a)-a(S + I)e_j^T}E(a + e_j,aS + a)
	\end{align*}
	
	\vspace{10mm}
	
	Consider the pointwise product
	\begin{align*}
		W^H \odot E(e_n, 0)W = \frac{1}{N} \sum_a i^{-w(a)} E(a, a(S + I)) \sum_b i^{w(b) - b(S + I)e_n^T} E(b + e_n, b(S + I))
	\end{align*}
	If $a \neq b \implies E(a, c) \odot E(b, d) = 0$ so this means that
	
	\begin{align*}
		&\frac{1}{N} \sum_a i^{-w(a)} E(a, a(S + I)) \sum_b i^{w(b) - b(S + I)e_n^T} E(b + e_n, b(S + I)) =\\ &\frac{1}{N}\sum_{a,b} \delta_{a, b + e_n} i^{-w(a)} i^{w(b)-b(S+I)e_n^T} E(a, a(S+I)) \odot E(b + e_n, b(S+I)) =\\
		&\frac{1}{N}\sum_{b} i^{w(b)-w(b+e_n)-b(S+I)e_n^T}E(b + e_n, e_n(S+I)) = \frac{1}{N} \sum_{b} i^{bb^T - (b+e_n)(b+e_n)^T - bS_n - be_n^T}E(b+e_n, S_n + e_n) = \\ &\frac{1}{N} \sum_{b} i^{b(e_n + S_n)^T - 1}E(b+e_n,S_n+e_n)
	\end{align*}
	The second vector $S_n+e_n$, that determines the signs, stays the same over the whole sum. Now notice that $E(b+e_n, S_n + e_n) = i^{(b+e_n)(S_n+e_n)^T}E(b + e_n, 0)E(0,S_n + e_n)$.
	\begin{align*}
		&\frac{1}{N} \sum_{b} i^{b(e_n + S_n)^T - 1}E(b+e_n,S_n+e_n)
		= \frac{1}{N} \sum_{b} i^{b(e_n + S_n)^T-1}i^{(b+e_n)(S_n+e_n)^T}E(b + e_n, 0)E(0,S_n + e_n) = \\ &\frac{1}{N} \left(\sum_{b} (-1)^{b(e_n+S_n)^T} E(b+e_n, 0) \right) i^{e_nS_n^T}E(0, S_n + e_n)
	\end{align*}
	Now 
	$\left[(-1)^{b(e_n+S_n)^T}\right]_{b \in \mathbb{F}_2^m}$ is a row of WHT matrix. 
	The $E(b+e_n,0)$-part fills the matrix in such a way that every column is a polynomial permutation of the row $\left[(-1)^{b(e_n+S_n)^T}\right]_{b \in \mathbb{F}_2^m}$ (this needs rigorous proof, but it holds expirimentally in Mathematica and intuitionally). Since the WHT-rows are $\pm 1$ eigenvectors with respect to polynomial permutations, we will get a matrix with $\pm 1$ the same WHT-row as every column. \newpage 
	
	If this matrix is multiplied by the WHT matrix $H$ we will get a following kind of matrix:
	
	\begin{align*}
		H \frac{1}{N} \left(\sum_{b} (-1)^{b(e_n+S_n)^T} E(b+e_n, 0) \right) i^{e_nS_n^T}E(0, S_n + e_n) = \frac{i^{e_nS_n^T}}{N}ME(0, S_n + e_n)
	\end{align*}
	where $M = \begin{pmatrix} 0 & 0 & \cdots & 0 \\
		\vdots & \vdots &  & \vdots \\
		0 & 0 &  & 0 \\
		m_1 & m_2 & \cdots & m_N \\
		0 & 0 & & 0 \\
		\vdots & \vdots &  & \vdots \\
		0 & 0 & \cdots & 0 \\
	\end{pmatrix}$ and now since $E(0, S_n + e_n)$ is just a diagonal matrix with some sign we get just the expected result. The whole matrix $\frac{i^{e_nS_n^T}}{N}ME(0, S_n + e_n)$ is just of form:
	\begin{align*}
		\frac{i^{e_nS_n^T}}{N} \begin{pmatrix} 0 & 0 & \cdots & 0 \\
			\vdots & \vdots &  & \vdots \\
			0 & 0 &  & 0 \\
			s_1m_1 & s_2m_2 & \cdots & s_Nm_N \\
			0 & 0 & & 0 \\
			\vdots & \vdots &  & \vdots \\
			0 & 0 & \cdots & 0 \\
		\end{pmatrix}
	\end{align*}
	
	This tells us that the shift-and-multiply operation gives an unique peak at a coordinate of a codeword, which determines a row of the $S$-matrix. The sign bits $s_1,...,s_N$ determine a bit at the $b$-vector, when the chirp is written in form $\left[i^{vSv^T + 2vb^T}\right]_{v \in \mathbb{F}^m_2}$.
	
	%\xrightarrow[\text{WHT}]{\text{}} \sum_b i^{w(b)-w(a)-b(S+I)e_n^T}E(e_n(S+I), b + e_n)
	%
	%\begin{align*}
	%    &E(a,a(S+I)) \cdot E(b+e_n,b(S+I)) = \delta_{a,b+e_n} E(a,  (b+e_n)(S+I) + b(S+I)) =  \delta_{a,b+e_n} E(a,  e_n(S+I))  =\\ &\delta_{a,b+e_n} E(a,  S_n+e_n)
	%\end{align*}
\end{document}